**Дата**: 30 ноября 2025 г.

**Статус**: Принято

**Контекст**:  
При разработке высоконагруженной платформы интернет-магазина нужно выбрать архитектурные паттерны, которые помогут выдержать требования по производительности (PER01–PER04), масштабируемости до 100 000 пользователей (SCA01–SCA04) и доступности 99.9% (AVA01).

Для разных частей системы подходы будут отличаться.
Для транзакционных данных (заказы, пользователи, платежи) важнее всего консистентность, поэтому используем **CP-подход**: запись идёт на мастер, чтение - с реплик, и нужно учитывать задержку репликации.
Для поиска, логирования и рекомендаций можно позволить eventual consistency, поэтому там подходят инструменты уровня **AP** (Elasticsearch, Kafka, Redis Streams).

**Рассмотренные варианты:**

1. **Трехзвенная архитектура**: Классическая схема из Frontend, Backend и Storage.
   Frontend раздаёт статику и балансирует нагрузку, Backend выполняет бизнес-логику, а Storage отвечает за базы данных, кеши, индексы и т. д.

2. **Кэширование**: Чтобы не нагружать базу и ускорять ответы, используем Redis. Данные кэшируются по ключам, а инвалидация происходит по событиям (например, обновили товар - сбросили кэш каталога).

3. **Толстый клиент (SPA)**: Часть логики переносится на клиент - пагинация, валидация форм, перехват ошибок, повтор запросов. API - REST или gRPC. Это снижает нагрузку на бэкенд.

4. **Деградация функциональности**: При пиковых нагрузках временно отключаем некритичные фичи (рекомендации, аналитика), чтобы критичные разделы сайта работали стабильно.

5. **Вертикальное масштабирование**: Увеличение ресурсов конкретного сервера (CPU, RAM, диски). Это помогает на старте, пока трафик ещё небольшой.

6. **Функциональное разделение**: Деление системы на отдельные сервисы по областям: каталог, пользователи, заказы и так далее. Уменьшает связанность и позволяет масштабировать сервисы независимо.

7. **Горизонтальное масштабирование**: Добавление серверов для увеличения пропускной способности. Stateless-бэкенды масштабируются независимо, нагрузка распределяется через балансировщики.

8. **Сервисно-ориентированная архитектура (SOA)**: Используем микросервисы как частный вариант SOA: небольшие независимые сервисы, которые общаются по REST/gRPC.

9. **Монолитное приложение**: Рассматривали как вариант, но отказались. Монолит сложно масштабировать и быстро обновлять.

10. **Отложенные вычисления**: Все тяжелые задачи, которые не влияют на ответ пользователю (обновление статистики, пересчёт рейтингов, генерация отчетов), выполняются в фоне.

11. **Очереди (асинхронная обработка)**: RabbitMQ или Kafka для фоновой обработки: отправка email/SMS, обработка изображений, интеграция с внешними API. Пользователь не ждёт завершения сложных операций.

12. **Конвейер**: Разбиение сложной задачи на этапы, каждый из которых выполняется независимо.

13. **Репликация базы данных**: PostgreSQL master–replica. На мастер идут записи, реплики используются для чтения. При сбое мастера - автоматический failover.

14. **Вертикальный шардинг**: Разные данные на разные физические серверы, разные СУБД/типы СУБД (например, пользователи в PostgreSQL, товары в MongoDB, поиск в Elasticsearch).

15. **Горизонтальный шардинг**: Делим таблицы по строкам, например, по user_id. Это позволяет масштабировать данные линейно.

16. **Виртуальные шарды**: Используем много логических шардов, которые распределяются по физическим нодам. При увеличении нагрузки переносим виртуальные шарды, не меняя код приложения.

17. **Центральный диспетчер**: Компонент, который направляет запросы на нужную базу или шард.

18. **Партиционирование**: Делим таблицы по датам или другим критериям. Например, "горячие" заказы лежат в одной партиции, старые - в архивных.

19. **Денормализация**: Дублируем некоторые данные (например, название товара в заказах), чтобы ускорить запросы без лишних JOIN.

20. **Введение избыточности**: Храним данные в нескольких хранилищах: PostgreSQL + Elasticsearch + Redis для ускорения поиска и повышения отказоустойчивости.

21. **Параллельное выполнение**: Запросы к различным сервисам (товар, отзывы, наличие, рекомендации) выполняются параллельно для ускорения генерации страницы.

22. **Специализированные серверы**: Выделение отдельных серверов и сервисов для специфических, ресурсоемких задач.

23. **Comet-сервер**: Push-уведомления для обновления статуса заказа или чатов поддержки. Основной сайт от этого не зависит, поэтому применяется точечно.

**Решение:**

- **Трехзвенная архитектура**
- **Кэширование**
- **Толстый клиент**
- **Деградация функциональности**
- **Вертикальное масштабирование**
- **Горизонтальное масштабирование**
- **Сервисно-ориентированная архитектура (микросервисы)**
- **Очереди (асинхронная обработка)**
- **Репликация базы данных**
- **Вертикальный шардинг**
- **Горизонтальный шардинг + виртуальные шарды**
- **Партиционирование**
- **Денормализация**
- **Параллельное выполнение**
- **Специализированные серверы**

**Обоснование:**

- **Трехзвенная архитектура** - удобная основа: фронтенд раздаёт статику, бэкенд выполняет бизнес-логику, всё хранение собрано в отдельном слое.
- **Кэширование** - серьёзно ускоряет выдачу каталога и профилей, снижает нагрузку на базу.
- **Толстый клиент** - уменьшает количество запросов и делает интерфейс отзывчивее.
- **Деградация функциональности** - помогает пережить пиковые нагрузки.
- **Вертикальное и горизонтальное масштабирование** - дают возможность двигаться "от простого к сложному" и плавно наращивать ресурсы.
- **Микросервисы** - проще развивать, масштабировать отдельно и внедрять новые фичи.
- **Очереди** - разгружают бэкенд, позволяя выполнять тяжёлые операции не блокируя пользователя.
- **Репликация и шардирование** - позволяют масштабировать данные и повышают отказоустойчивость.
- **Партиционирование и денормализация** - ускоряют чтение и уменьшают нагрузку на базу данных.
- **Параллельное выполнение** - ускоряет запросы, которые собирают данные из разных сервисов.
- **Специализированные серверы** - эффективнее, чем универсальная СУБД для всего.

**Недостатки решения:**

- Чем больше сервисов, тем больше точек отказа и сложнее мониторинг.
- Eventual consistency в поиске и аналитике может давать задержки обновления данных.
- Межсервисная коммуникация увеличивает задержки и требует хорошей сети.
- Отладка распределённых систем сложнее.
- Нужно следить за версиями API между сервисами.
- Возможны каскадные отказы при неправильных настройках таймаутов и повторов.

**Последствия:**

- Увеличение затрат на инфраструктуру и мониторинг.
- Нужно развивать практики SRE и автоматизацию развертывания.
- Придётся поддерживать разные типы бэкапов (PostgreSQL, Redis, Elasticsearch и т. д.).
- Сложнее тестировать всю систему целиком: интеграционные тесты, нагрузочные тесты и т. д.
- Требуется хорошая документация API и схем взаимодействия между сервисами.
